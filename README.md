# AI Chat Application

A multi-AI chat interface with a secure backend. The API keys are stored safely on the server, not exposed in the frontend.

## Setup Instructions

### 1. Install Dependencies

```bash
npm install
```

### 2. Configure Environment Variables

Create a `.env` file in the root directory:

```env
OPENROUTER_API_KEY=your-api-key-here
PORT=3000
```

Replace `your-api-key-here` with your actual OpenRouter API key.

**Get your API key from:** https://openrouter.ai/keys

### 3. Start the Server

```bash
npm start
```

The server will run on `http://localhost:3000`

### 4. Open the Application

Open your browser and go to:
```
http://localhost:3000/Roastify.html
```

Or if you have the HTML file open directly, make sure the backend is running!

## Features

- ğŸ”’ **Secure**: API keys are stored on the backend, never exposed to clients
- ğŸ¤– **Multi-AI Support**: Switch between different AI models
- ğŸ’¬ **Continuous Chat**: Maintains conversation history per model
- ğŸ¨ **Modern UI**: Clean, dark-themed interface

## Available AI Models

- Gemini 2.5 Flash
- GPT-4o
- Claude 3.5 Sonnet
- Gemini Pro
- Llama 3.1

## Project Structure

```
â”œâ”€â”€ server.js          # Backend server (handles API requests)
â”œâ”€â”€ package.json       # Node.js dependencies
â”œâ”€â”€ .env              # Environment variables (API keys) - NOT in git
â”œâ”€â”€ .gitignore        # Git ignore file
â”œâ”€â”€ Roastify.html     # Frontend chat interface
â””â”€â”€ README.md         # This file
```

## Security Notes

- âœ… API keys are stored in `.env` file (never commit this to git)
- âœ… Frontend makes requests to your backend, not directly to OpenRouter
- âœ… Backend validates requests before forwarding to OpenRouter
- âŒ Never commit `.env` file to version control

## Troubleshooting

**Server won't start:**
- Make sure Node.js is installed: `node --version`
- Install dependencies: `npm install`
- Check if port 3000 is already in use

**API errors:**
- Verify your API key in `.env` file is correct
- Check that the server is running
- Look at server console for error messages
